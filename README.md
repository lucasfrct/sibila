# Sibila - Sistema RAG para AnÃ¡lise de Documentos JurÃ­dicos

As sibilas eram figuras da mitologia inspiradas pelos deuses para profetizar. Esse repositÃ³rio implementa um sistema avanÃ§ado de **RAG (Retrieval Augmented Generation)** especializado em anÃ¡lise de documentos jurÃ­dicos, capaz de responder perguntas baseadas em documentos fornecidos pelo usuÃ¡rio atravÃ©s de inteligÃªncia artificial.

## ğŸ¯ VisÃ£o Geral do Sistema

Sibila Ã© uma aplicaÃ§Ã£o Python que combina processamento de linguagem natural, bancos de dados vetoriais e modelos de linguagem para criar um assistente inteligente para anÃ¡lise documental. O sistema processa documentos PDF (especialmente legislaÃ§Ã£o), extrai conhecimento estruturado e fornece respostas precisas atravÃ©s de uma API REST.

## ğŸš€ Como Executar Localmente

### ConfiguraÃ§Ã£o RÃ¡pida

1. **Clone o repositÃ³rio**
```bash
git clone https://github.com/lucasfrct/sibila.git
cd sibila
```

2. **Configure o ambiente**
```bash
cp .env.example .env
```

3. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

4. **Instale e configure o Ollama**
```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Iniciar o servidor Ollama
ollama serve

# Em outro terminal, baixar o modelo
ollama pull llama3
```

5. **Execute a aplicaÃ§Ã£o**
```bash
python main.py
```

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em `http://localhost:3000`

### ExecuÃ§Ã£o sem Hot Reload
```bash
python main.py --no-reload
```

### ğŸ“– Guia Completo
Para instruÃ§Ãµes detalhadas, consulte: **[SETUP_LOCAL.md](./SETUP_LOCAL.md)**

## ğŸ—ï¸ Arquitetura do Sistema

### Pipeline de Processamento de Documentos

O sistema implementa um pipeline sofisticado para processamento de documentos PDF:

#### 1. **MÃ³dulo de Leitura (`src/modules/document/reader.py`)**
- **Biblioteca principal**: `pdfplumber` para extraÃ§Ã£o precisa de texto
- **Funcionalidades**:
  - Leitura completa de documentos PDF
  - ExtraÃ§Ã£o de pÃ¡ginas especÃ­ficas com controle de intervalo
  - MecÃ¢nica de limite de pÃ¡ginas com validaÃ§Ã£o automÃ¡tica
  - Tratamento de erros e logging detalhado

#### 2. **Sistema de Metadados (`src/modules/document/`)**
- **Metadados de pÃ¡gina** (`page_metadata.py`): InformaÃ§Ãµes estruturais de cada pÃ¡gina
- **Metadados de parÃ¡grafo** (`paragraph_metadata.py`): SegmentaÃ§Ã£o em parÃ¡grafos com posicionamento
- **Metadados de frase** (`phrase_metadata.py`): Granularidade no nÃ­vel de sentenÃ§a
- **RepositÃ³rios de dados**: PersistÃªncia SQLite com padrÃ£o Repository

#### 3. **AnÃ¡lise de LegislaÃ§Ã£o (`src/modules/analysis/legislation.py`)**
- **DivisÃ£o automÃ¡tica em artigos**: Regex avanÃ§ado para identificar estrutura legal
- **ClassificaÃ§Ã£o de categorias jurÃ­dicas**:
  - Direito Constitucional, Trabalhista, Civil, Penal
  - Direito Administrativo, TributÃ¡rio, Ambiental, etc.
- **IdentificaÃ§Ã£o de tipos normativos**: Lei, Decreto, Portaria, ResoluÃ§Ã£o, etc.
- **Sistema de eficÃ¡cia normativa**: Plena, Limitada, Contida

### Sistema de Processamento de Linguagem Natural

#### 1. **MÃ³dulo NLP (`src/modules/nlp/`)**

**Bag of Words (BoW)** (`bow.py`):
```python
# GeraÃ§Ã£o de vocabulÃ¡rio com sklearn CountVectorizer
def generate_bow(content: str) -> dict:
    processed_content = Str.removal_stopwords(content)
    vectorizer = CountVectorizer()
    bow = vectorizer.fit_transform([processed_content])
    # Retorna dicionÃ¡rio palavra: frequÃªncia
```

**ClassificaÃ§Ã£o de Texto** (`classifier.py`):
- **Algoritmo**: RegressÃ£o LogÃ­stica com TF-IDF
- **Pipeline**: VetorizaÃ§Ã£o â†’ Treinamento â†’ PrediÃ§Ã£o
- **PersistÃªncia**: Modelos salvos em formato joblib
- **AvaliaÃ§Ã£o**: Classification report do scikit-learn

**AnÃ¡lise de Sentimento** (`sentiment.py`):
- ClassificaÃ§Ã£o emocional de textos jurÃ­dicos
- IntegraÃ§Ã£o com pipeline de anÃ¡lise de documentos

**ExtraÃ§Ã£o de Features** (`featureextractor.py`):
- CaracterÃ­sticas linguÃ­sticas relevantes para classificaÃ§Ã£o
- OtimizaÃ§Ã£o para domÃ­nio jurÃ­dico

#### 2. **PrÃ©-processamento AvanÃ§ado**
- **RemoÃ§Ã£o de stop words**: Lista customizada para portuguÃªs jurÃ­dico
- **NormalizaÃ§Ã£o de texto**: Tratamento de caracteres especiais
- **TokenizaÃ§Ã£o inteligente**: PreservaÃ§Ã£o de termos jurÃ­dicos especÃ­ficos

### Banco de Dados Vetorial e RecuperaÃ§Ã£o

#### ChromaDB Integration (`src/modules/database/chromadbvector.py`)

**ConfiguraÃ§Ã£o do Cliente**:
```python
def client(path: str = "./data/.chromadb") -> chromadb.ClientAPI:
    return chromadb.PersistentClient(path=path)
```

**Funcionalidades principais**:
- **Armazenamento vetorial**: Embeddings de documentos e chunks
- **Busca por similaridade**: RecuperaÃ§Ã£o baseada em distÃ¢ncia cossenoidal
- **GestÃ£o de coleÃ§Ãµes**: OrganizaÃ§Ã£o hierÃ¡rquica de documentos
- **DetecÃ§Ã£o de conflitos**: PrevenÃ§Ã£o de duplicaÃ§Ã£o de IDs
- **IndexaÃ§Ã£o HNSW**: Performance otimizada para buscas aproximadas

### IntegraÃ§Ã£o com Modelos de Linguagem

#### 1. **Suporte Dual para LLMs (`src/models/`)**

**Ollama Local** (`ollama.py`):
```python
class ModelOllama:
    def __init__(self, model: str = "sibila"):
        self.client = ollama
        self.temperature = 0.5           # Controle de aleatoriedade
        self.max_tokens = 4096          # Limite de tokens de saÃ­da
        self.context = 2048             # Janela de contexto
        self.diffusion_of_hallucination = 0.8  # Anti-alucinaÃ§Ã£o
```

**OpenAI Cloud** (`open_ai.py`):
- IntegraÃ§Ã£o com API oficial da OpenAI
- Fallback para quando Ollama nÃ£o estÃ¡ disponÃ­vel
- Suporte a modelos GPT-3.5/GPT-4

#### 2. **Sistema de Prompts AvanÃ§ado (`src/modules/prompts/prompts.py`)**

**Persona de BibliotecÃ¡rio IA**:
```python
def resume(documents: str) -> str:
    prompt_template = """VocÃª Ã© um assistente de IA com experiÃªncia de um bibliotecÃ¡rio organizado.
    VocÃª tem uma alta capacidade de organizar ideias, documentos, assuntos e sessÃµes.
    Os documentos abaixo apresentam as fontes atualizadas e devem ser consideradas como verdade.
    Suas respostas sÃ£o apenas baseadas no documento e nÃ£o deve inventar, adicionar ou alucinar.
    Gere um resumo de no mÃ¡ximo 50 palavras...
    """
```

**Tipos de prompts implementados**:
- **Keywords**: ExtraÃ§Ã£o de palavras-chave relevantes
- **Resume**: Resumos concisos de documentos
- **Names**: IdentificaÃ§Ã£o de pessoas e autores citados
- **Publisher**: IdentificaÃ§Ã£o de editoras e fontes

### API REST e Endpoints

#### Estrutura da API (`src/routes/routes.py`)

**Endpoints principais**:
- `GET /api/v1/health` - Status do sistema
- `GET /api/v1/dataset` - Listagem de datasets disponÃ­veis
- `GET /api/v1/corpus` - Listagem do corpus gerado
- `POST /api/v1/corpus/generate` - GeraÃ§Ã£o assÃ­ncrona de corpus

**Endpoints planejados** (comentados):
- `/api/v1/catalog/search` - Busca no catÃ¡logo
- `/api/v1/catalog/indexer` - IndexaÃ§Ã£o de documentos
- `/api/v1/completions` - Chat completions
- `/api/v1/completions/history` - HistÃ³rico de conversas

### GeraÃ§Ã£o e AnÃ¡lise de Corpus

#### Sistema de Corpus (`src/modules/corpus/corpus.py`)

**Processamento multithread**:
```python
def doc_with_articles(path: str, page_init: int = 1, page_final: int = -1):
    doc_info = DocService.info(path)
    doc_file = DocService.pdf_content(doc['path'], page_init, page_final)
    doc['articles'] = Legislation.split_into_articles(doc_file)
    return doc
```

**Features do sistema de corpus**:
- **ExtraÃ§Ã£o automÃ¡tica de artigos**: Regex pattern matching para estrutura legal
- **AnotaÃ§Ã£o inteligente**: LLM auxilia na categorizaÃ§Ã£o e resumo
- **Processamento assÃ­ncrono**: ThreadPoolExecutor para performance
- **Controle de progresso**: Shared memory counters para tracking
- **ExportaÃ§Ã£o CSV**: Formato estruturado para anÃ¡lise posterior

### Sistema de CatÃ¡logaÃ§Ã£o

#### MÃ³dulo de CatÃ¡logo (`src/modules/catalog/`)

**Classe Catalog** (`catalog.py`):
```python
@dataclass
class Catalog:
    id: int = 0
    path: str = ""
    name: str = ""
    size: int = 0
    pages: int = 1
    mimetype: str = ""
    title: str = ""
    resume: str = ""
    categories: str = ""
```

**Funcionalidades**:
- **IndexaÃ§Ã£o automÃ¡tica**: Metadados extraÃ­dos automaticamente
- **CategorizaÃ§Ã£o**: ClassificaÃ§Ã£o por Ã¡rea jurÃ­dica
- **Busca semÃ¢ntica**: IntegraÃ§Ã£o com ChromaDB
- **RepositÃ³rio de dados**: PersistÃªncia e recuperaÃ§Ã£o otimizada

## ğŸ“Š Stack TecnolÃ³gico Detalhado

### Core Framework
- **Flask 3.0.3**: Framework web Python com suporte assÃ­ncrono
- **Python 3.9+**: Linguagem base com type hints

### Processamento de Documentos
- **pdfplumber 0.11.1**: ExtraÃ§Ã£o precisa de texto de PDFs
- **PDFMiner.six**: Parser avanÃ§ado de estrutura PDF
- **PyPDF2 3.0.1**: ManipulaÃ§Ã£o de metadados PDF

### Machine Learning & NLP
- **scikit-learn 1.5.0**: ClassificaÃ§Ã£o e vetorizaÃ§Ã£o
- **spaCy 3.7.5**: Processamento de linguagem natural
- **NLTK 3.8.1**: Toolkit de processamento linguÃ­stico
- **transformers** (via Ollama): Modelos transformer

### Banco de Dados
- **ChromaDB 0.5.3**: Banco vetorial com HNSW indexing
- **SQLite**: Banco relacional para metadados
- **chroma-hnswlib 0.7.3**: OtimizaÃ§Ã£o de indexaÃ§Ã£o

### IntegraÃ§Ã£o LLM
- **ollama 0.3.3**: Cliente para modelos locais
- **openai 1.10.0**: Cliente oficial OpenAI
- **httpx 0.27.0**: Cliente HTTP assÃ­ncrono

### UtilitÃ¡rios e Suporte
- **asyncio**: ProgramaÃ§Ã£o assÃ­ncrona nativa
- **joblib 1.4.2**: SerializaÃ§Ã£o de modelos ML
- **tqdm 4.66.2**: Barras de progresso
- **python-dotenv 1.0.1**: ConfiguraÃ§Ã£o via variÃ¡veis de ambiente

## ğŸ—‚ï¸ Estrutura de DiretÃ³rios

```
sibila/
â”œâ”€â”€ src/                    # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ config/            # ConfiguraÃ§Ãµes (Ollama, OpenAI)
â”‚   â”œâ”€â”€ models/            # IntegraÃ§Ãµes com LLMs
â”‚   â”œâ”€â”€ modules/           # MÃ³dulos funcionais
â”‚   â”‚   â”œâ”€â”€ analysis/      # AnÃ¡lise jurÃ­dica
â”‚   â”‚   â”œâ”€â”€ catalog/       # Sistema de catalogaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ corpus/        # GeraÃ§Ã£o de corpus
â”‚   â”‚   â”œâ”€â”€ database/      # Bancos de dados
â”‚   â”‚   â”œâ”€â”€ document/      # Processamento de documentos
â”‚   â”‚   â”œâ”€â”€ nlp/          # Processamento de linguagem
â”‚   â”‚   â”œâ”€â”€ prompts/      # Sistema de prompts
â”‚   â”‚   â”œâ”€â”€ response/     # FormataÃ§Ã£o de respostas
â”‚   â”‚   â””â”€â”€ viz/          # VisualizaÃ§Ãµes
â”‚   â”œâ”€â”€ routes/           # Endpoints da API
â”‚   â”œâ”€â”€ routines/         # Rotinas de migraÃ§Ã£o
â”‚   â”œâ”€â”€ utils/            # UtilitÃ¡rios diversos
â”‚   â””â”€â”€ server.py         # ConfiguraÃ§Ã£o Flask
â”œâ”€â”€ dataset/              # Dados de treinamento
â”‚   â”œâ”€â”€ sources/         # Documentos fonte (PDFs)
â”‚   â”œâ”€â”€ corpus/          # Corpus processado (CSV)
â”‚   â””â”€â”€ _library/        # Biblioteca de referÃªncia
â”œâ”€â”€ data/                # PersistÃªncia de dados
â”‚   â””â”€â”€ .chromadb/       # Banco vetorial ChromaDB
â”œâ”€â”€ tests/               # Testes automatizados
â””â”€â”€ main.py             # Ponto de entrada da aplicaÃ§Ã£o
```

## ğŸ”„ Fluxo de Dados do Sistema

### 1. **IngestÃ£o de Documentos**
```
PDF Input â†’ pdfplumber â†’ Text Extraction â†’ Metadata Generation â†’ SQLite Storage
```

### 2. **Processamento de Corpus**
```
Legal Documents â†’ Article Splitting â†’ LLM Annotation â†’ ChromaDB Indexing â†’ CSV Export
```

### 3. **Pipeline RAG**
```
User Query â†’ Embedding Generation â†’ Vector Search â†’ Context Retrieval â†’ LLM Completion â†’ Structured Response
```

### 4. **AnÃ¡lise JurÃ­dica**
```
Legal Text â†’ Category Classification â†’ Normative Type â†’ Efficacy Analysis â†’ Structured Metadata
```

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente (.env)
```bash
OPENAI_API_KEY=        # Chave API OpenAI (opcional)
OLLAMA_PROXY_URL=      # URL proxy Ollama (opcional)
```

### ParÃ¢metros do Modelo Ollama
```python
temperature = 0.5                    # Controle de aleatoriedade (0.0-1.0)
max_tokens = 4096                   # Limite de tokens de saÃ­da
context = 2048                      # Janela de contexto
diffusion_of_hallucination = 0.8   # Anti-alucinaÃ§Ã£o (0.0-1.0)
diversification_rate = 0.0         # Taxa de diversificaÃ§Ã£o
penalty_rate = 1.1                 # PenalizaÃ§Ã£o de repetiÃ§Ã£o
```

## ğŸ¯ Casos de Uso EspecÃ­ficos

### 1. **AnÃ¡lise de LegislaÃ§Ã£o**
- Processamento automÃ¡tico da ConstituiÃ§Ã£o Federal
- ExtraÃ§Ã£o de artigos e incisos
- CategorizaÃ§Ã£o por Ã¡rea jurÃ­dica
- GeraÃ§Ã£o de resumos e palavras-chave

### 2. **Busca SemÃ¢ntica em Documentos**
- Consultas em linguagem natural
- RecuperaÃ§Ã£o baseada em similaridade
- CitaÃ§Ã£o automÃ¡tica de fontes
- Ranking de relevÃ¢ncia

### 3. **Assistente JurÃ­dico IA**
- Respostas baseadas apenas em documentos
- PrevenÃ§Ã£o de alucinaÃ§Ãµes
- Formato de resposta estruturado
- Rastreabilidade de fontes

## ğŸš€ Roadmap e Funcionalidades Planejadas

### Implementadas âœ…
- [x] Pipeline completo de processamento de PDF
- [x] IntegraÃ§Ã£o dual LLM (Ollama + OpenAI)
- [x] Sistema de corpus jurÃ­dico
- [x] Banco vetorial ChromaDB
- [x] API REST bÃ¡sica
- [x] Sistema de classificaÃ§Ã£o NLP
- [x] AnÃ¡lise de documentos legais

### Em Desenvolvimento ğŸ”„
- [ ] Endpoints de busca e completions
- [ ] Interface web frontend
- [ ] Sistema de cache inteligente
- [ ] MÃ©tricas de performance
- [ ] Testes automatizados

### Planejado ğŸ“‹
- [ ] Suporte a mÃºltiplos formatos (DOCX, TXT)
- [ ] Sistema de usuÃ¡rios e permissÃµes
- [ ] Dashboard de analytics
- [ ] Deployment containerizado
- [ ] CI/CD pipeline

## ğŸ“ Conceitos TÃ©cnicos AvanÃ§ados

### RAG (Retrieval Augmented Generation)
O sistema implementa RAG atravÃ©s da combinaÃ§Ã£o de:
- **Retrieval**: ChromaDB para busca vetorial
- **Augmentation**: Context injection nos prompts
- **Generation**: LLM (Ollama/OpenAI) para respostas

### Embeddings e Similaridade
- VetorizaÃ§Ã£o de documentos usando modelos transformer
- Busca por similaridade cossenoidal
- IndexaÃ§Ã£o HNSW para performance

### Anti-AlucinaÃ§Ã£o
- Prompts restritivos: "baseado apenas no documento"
- ParÃ¢metro `diffusion_of_hallucination`
- ValidaÃ§Ã£o de respostas contra fonte

Para inicializar o servidor em modo de desenvolvimento: `python main.py`  
Para desativar hot reload: `python main.py --no-reload`
