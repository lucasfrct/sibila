# Sibila - Sistema RAG para AnÃ¡lise de Documentos JurÃ­dicos

Sistema avanÃ§ado de **RAG (Retrieval Augmented Generation)** especializado em anÃ¡lise de documentos jurÃ­dicos, utilizando IA para responder perguntas baseadas em documentos fornecidos pelo usuÃ¡rio.

## ğŸ¯ VisÃ£o Geral

Sibila combina processamento de linguagem natural, bancos de dados vetoriais e modelos de linguagem para criar um assistente inteligente de anÃ¡lise documental. Processa documentos PDF (especialmente legislaÃ§Ã£o), extrai conhecimento estruturado e fornece respostas precisas via API REST.

## ğŸš€ InstalaÃ§Ã£o e Uso

### 1. PreparaÃ§Ã£o do Ambiente
```bash
git clone https://github.com/lucasfrct/sibila.git
cd sibila
cp .env.example .env
pip install -r requirements.txt
```

### 2. ConfiguraÃ§Ã£o do Ollama
```bash
# Instalar e iniciar Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve

# Em outro terminal, baixar modelo
ollama pull llama3
```

### 3. Executar AplicaÃ§Ã£o
```bash
python main.py              # Com hot reload
python main.py --no-reload  # Sem hot reload
```

**Acesso:** `http://localhost:3000`

**DocumentaÃ§Ã£o completa:** [SETUP_LOCAL.md](./SETUP_LOCAL.md)

### 4. GestÃ£o do Banco de Dados
```bash
# Verificar status das migraÃ§Ãµes
python migrate_cli.py status

# Aplicar migraÃ§Ãµes pendentes
python migrate_cli.py migrate

# Criar nova migraÃ§Ã£o
python migrate_cli.py create "Adicionar nova tabela"
```

**DocumentaÃ§Ã£o do sistema de migraÃ§Ã£o:** [DATABASE_MIGRATION_GUIDE.md](./DATABASE_MIGRATION_GUIDE.md)

## ğŸ—ï¸ Arquitetura do Sistema

### Pipeline de Processamento
1. **Leitura de PDFs** (`src/modules/document/reader.py`) - ExtraÃ§Ã£o precisa com pdfplumber
2. **AnÃ¡lise JurÃ­dica** (`src/modules/analysis/legislation.py`) - ClassificaÃ§Ã£o automÃ¡tica de artigos
3. **Processamento NLP** (`src/modules/nlp/`) - ClassificaÃ§Ã£o de texto e anÃ¡lise de sentimento
4. **Banco Vetorial** (`src/modules/database/chromadbvector.py`) - ChromaDB para busca semÃ¢ntica
5. **Modelos LLM** (`src/models/`) - IntegraÃ§Ã£o Ollama/OpenAI para geraÃ§Ã£o de respostas

### Fluxo RAG
```
PDF â†’ ExtraÃ§Ã£o â†’ AnÃ¡lise â†’ VetorizaÃ§Ã£o â†’ ChromaDB â†’ Query â†’ LLM â†’ Resposta
```

## ğŸ“Š Stack TecnolÃ³gico

**Core:** Python 3.9+, Flask 3.1.1  
**Processamento:** pdfplumber, PyPDF2, scikit-learn, NLTK  
**IA/ML:** Ollama, OpenAI, ChromaDB, transformers  
**Banco:** SQLite (metadados), ChromaDB (vetorial)

## ğŸ—‚ï¸ Estrutura de DiretÃ³rios

```
sibila/
â”œâ”€â”€ src/                      # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ config/              # ConfiguraÃ§Ãµes (Ollama, OpenAI)
â”‚   â”œâ”€â”€ models/              # IntegraÃ§Ãµes com LLMs
â”‚   â”œâ”€â”€ modules/             # MÃ³dulos funcionais
â”‚   â”‚   â”œâ”€â”€ analysis/        # AnÃ¡lise jurÃ­dica
â”‚   â”‚   â”œâ”€â”€ catalog/         # Sistema de catalogaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ corpus/          # GeraÃ§Ã£o de corpus
â”‚   â”‚   â”œâ”€â”€ database/        # Bancos de dados (ChromaDB, SQLite)
â”‚   â”‚   â”œâ”€â”€ document/        # Processamento de documentos
â”‚   â”‚   â”œâ”€â”€ nlp/             # Processamento de linguagem
â”‚   â”‚   â”œâ”€â”€ prompts/         # Sistema de prompts
â”‚   â”‚   â”œâ”€â”€ response/        # FormataÃ§Ã£o de respostas
â”‚   â”‚   â””â”€â”€ viz/             # VisualizaÃ§Ãµes
â”‚   â”œâ”€â”€ routes/              # Endpoints da API
â”‚   â”œâ”€â”€ routines/            # Rotinas de migraÃ§Ã£o
â”‚   â”œâ”€â”€ utils/               # UtilitÃ¡rios diversos
â”‚   â””â”€â”€ server.py            # ConfiguraÃ§Ã£o Flask
â”œâ”€â”€ dataset/                 # Dados de treinamento
â”‚   â”œâ”€â”€ sources/            # Documentos fonte (PDFs)
â”‚   â”œâ”€â”€ corpus/             # Corpus processado (CSV)
â”‚   â””â”€â”€ _library/           # Biblioteca de referÃªncia
â”œâ”€â”€ data/                   # PersistÃªncia de dados
â”‚   â””â”€â”€ .chromadb/         # Banco vetorial ChromaDB
â”œâ”€â”€ tests/                  # Testes automatizados
â””â”€â”€ main.py                # Ponto de entrada da aplicaÃ§Ã£o
```

## ğŸ”„ Principais Funcionalidades

- **Processamento de Documentos**: Leitura de PDFs, geraÃ§Ã£o de metadados e conversÃ£o para texto
- **AnÃ¡lise JurÃ­dica**: ClassificaÃ§Ã£o automÃ¡tica de categorias, tipos normativos e eficÃ¡cia
- **Sistema de Corpus**: ExtraÃ§Ã£o de artigos e anotaÃ§Ãµes automÃ¡ticas via LLM
- **Banco Vetorial**: Armazenamento e busca semÃ¢ntica via ChromaDB
- **API REST**: Endpoints para corpus, datasets e health check
- **Modelos LLM**: IntegraÃ§Ã£o dual com Ollama e OpenAI

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente (.env)
```bash
OPENAI_API_KEY=        # Chave API OpenAI (opcional)
OLLAMA_PROXY_URL=      # URL proxy Ollama (opcional)
```

### ParÃ¢metros do Modelo
- `temperature`: Controle de aleatoriedade (0.0-1.0)
- `max_tokens`: Limite de tokens de saÃ­da (4096)
- `context`: Janela de contexto (2048)
- `diffusion_of_hallucination`: Anti-alucinaÃ§Ã£o (0.8)
