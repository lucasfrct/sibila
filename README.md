# Sibila S√≠nica

As sibilas eram figuras da mitologia inspiradas pelos deuses para profetizar.

Esse reposit√≥rio √© um exemplo de aplica√ß√£o capaz de responder perguntas baseadas em documentos fornecidos pelo usu√°rio.

## üöÄ Como Executar Localmente

### Configura√ß√£o R√°pida

1. **Clone o reposit√≥rio**
```bash
git clone https://github.com/lucasfrct/sibila.git
cd sibila
```

2. **Configure o ambiente**
```bash
cp .env.example .env
```

3. **Instale as depend√™ncias**
```bash
pip install -r requirements.txt
```

4. **Instale e configure o Ollama**
```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Iniciar o servidor Ollama
ollama serve

# Em outro terminal, baixar o modelo
ollama pull llama3
```

5. **Execute a aplica√ß√£o**
```bash
python main.py
```

A aplica√ß√£o estar√° dispon√≠vel em `http://localhost:5000`

### üìñ Guia Completo
Para instru√ß√µes detalhadas, consulte: **[SETUP_LOCAL.md](./SETUP_LOCAL.md)**

## Estrutura de containers

- `ollama`: A LLM pode ser acessada em <http://localhost:11434>

### Para Executar a aplica√ß√£o

Tudo est√° sendo constru√≠do em docker, e `docker-compose` √© o gerenciador para rodar tudo em desenvolvimento

```docker-compose up -d```

### Ambiente de desenvolvimento

Para rodar a aplica√ß√£o em desenvolvimento, basta rodar o comando abaixo

``` python ./main.py ```

Para rodar a aplica√ß√£o sem hot reload, basta rodar o comando abaixo

``` python ./main.py --no-reload ```

### Estrutura de diret√≥rios

- `./data`: A pasta √© a persist√™ncia dos bancos de dados usados no projeto
- `./dataset`: A pasta com os arquivos de treinamento do modelo e inicializa√ß√£o do banco de dados

### LLM Llama 3

O Meta treinou o Llama 3 com uma contagem de tokens de mais de 15 trilh√µes de tokens.

O modelo 8B tem um limite de conhecimento de mar√ßo de 2023.

O modelo 70B tem um limite de conhecimento de dezembro de 2023.

Os modelos usam Grouped-Query Attention (GQA).

SFT √© uma t√©cnica de treinamento que permite que o modelo seja treinado em um conjunto de dados de treinamento muito maior do que o que pode ser armazenado na mem√≥ria de uma √∫nica GPU.

### Anota√ß√µes

- classificador: <https://medium.com/@andsouit/classificador-de-inten%C3%A7%C3%A3o-com-o-tensorflow-f7fbc854f643>
- LM Studio = interface web para conversar com  o LLM
- Hugging Face: Tom Jobbins
- reposit√≥rio de livros de tecnologia: <https://github.com/free-educa/books/blob/main/books/Design_Patterns.pdf>
